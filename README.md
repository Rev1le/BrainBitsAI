# BrainBitsAI


## II Emotion kids
 В нашем проекте представлен искусственный интеллект способный распознавать эмоции учащихся для оценки качества образовательного процесса, а так же выявления детей, нуждающихся в психологической помощи.
Существует интерфейс выбора видео, фото, строящий графиков, который анализирует эмоции сканируемых людей с точностью от 62,5 %.

Данный программнный продукт использует Yolo-V5 и RepVGG для обнаружения выражений лица и классификации эмоций (дополнительную информацию о том, как это работает, см. в архитектуре). Чтобы узнать, как использовать код, ознакомьтесь с разделом "Запуск продукта" использования для получения дополнительной информации.


## Для теста 
-  Установить все зависмости проекта из файла requirements.txt 
-  запустить testing_script.py
-  Вставить в консоль путь до папки с видео



## Уникальность
Реализована многопоточность, быстродействие, удобный вывод информации, экономия ресурсов заказчика, легко интегрируемая система. 



## Проблематика
В ходе реализации столкнулись с проблемой, предложенный data cet "FET 2013", имеющий размер 30 000 фотографий не достаточен для обучения модели. Поэтому была использована нейросеть, обученная на data set "AffectNET".

## Запуск продукта

Для запуска продукта используется Python скрипт  `__init__.py`. В _config.json_ прописываются пути
для папки с лицами и с видео (url ссылкой) на основе которого будет работать продукт. При открытии скрипта у вас есть несколько кпонок:
-   Общая эмоция, при нажатии указываем путь к видео
-   Эмоции человека, при нажатии 
-   Выход при нажатии закрывается окно

## Виды эмоций
-    Злость 
-    Отвращение
-    Страх
-    Радость
-    Грусть
-    Удивление
-    Нейтральное состояние


## Архтектура 
Программный продукт состоит из двух частей распознавание лиц и распознавание эмоций

## Распознавание лиц

Это репозиторий является ответвлением ultralytics/Yolo-V5, так как код используется для классификации лиц. Подробнее о [Yolo-V5"]: https://github.com/ultralytics/yolov5 читайте здесь. Для обнаружения лиц модель была обучена на наборе данных WIDER FACE, который содержит 393 703 лица. Для получения дополнительной информации ознакомьтесь с документом здесь.

## Распознавание эмоций
Этот репозиторий использует нейросеть RepVGG. Несмотря на то, что это основная модель, было бы разумнее разветвить репозиторий Yolo-V5, поскольку он был более сложным. Модель обучалась на наборе данных AffectNet, который содержит 420 299 выражений лица.



